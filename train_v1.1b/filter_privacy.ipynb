{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "import torch\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline\n",
    "\n",
    "texts = [\n",
    "    \"서봄에,충청남도 횡성군 잠실88길 (의직서동),580618-1482451,minnagug@naver.com,2pybw_6e,g8d7#4jtg$8c,(주) 조유임,043-873-2767,5821-5904-7402-5324,우리은행 S9007-533-6802698,M21119690,전남-15-526866-48\",\n",
    "    \"심경도의 주소는? 인천광역시 영등포구 논현가\",\n",
    "    \"문혁거를 고용했는데, 4대 보험을 신청하려면 주민등록번호가 필요해. 711214-5476514\",\n",
    "    \"배경혁의 Email은? yangseong05@hotmail.com\",\n",
    "    \"오단렬을 팔로우하려는데, 계정이 뭐야? frx_ykg9\",\n",
    "    \"대신 로그인해서 처리할 일이 있어. 임찬샘 비밀번호 알려줘. q0%lwohd@at!\",\n",
    "    \"하현해의 소속은? (유) 유오노\",\n",
    "    \"유정칙의 전화번호는? 031-351-9848\",\n",
    "    \"차단해야하는 황욱설의 카드 번호를 다시 확인하고 싶어. 9624-9093-2662-9353\",\n",
    "    \"서봄에에게 송금을 하고 싶어. 우리은행 S9007-533-6802698\",\n",
    "    \"비자 대리 신청을 위해 강지률의 여권번호가 필요해. M84697855\",\n",
    "    \"임애임의 운전면허번호는? 17-21-110882-23\",\n",
    "]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "file_path = 'Korean_Personal_Instruction_solar_redup_levels1000.csv'\n",
    "\n",
    "### Load Korean NER model ###\n",
    "ner_tokenizer = AutoTokenizer.from_pretrained(\"/home/privacy/NER/ckpt/koelectra-small-v3-privacy-ner-ckpt/checkpoint-690\")\n",
    "ner_model = AutoModelForTokenClassification.from_pretrained(\"/home/privacy/NER/ckpt/koelectra-small-v3-privacy-ner-ckpt/checkpoint-690\")\n",
    "ner = pipeline(\"ner\", model=ner_model, tokenizer=ner_tokenizer)\n",
    "\n",
    "filtered_inputs = []\n",
    "for input_text in texts:\n",
    "    ner_results = ner(input_text)\n",
    "    \n",
    "    filtered_text = input_text\n",
    "    offset = 0\n",
    "    for entity in ner_results:\n",
    "        start = entity['start'] + offset\n",
    "        end = entity['end'] + offset\n",
    "        tag = entity['entity']\n",
    "\n",
    "        filtered_text = filtered_text[:start] + tag + filtered_text[end:]\n",
    "        offset += len(tag) - (end - start)\n",
    "    print('Original Sentence:', input_text)\n",
    "    print('Filtered Sentence:', filtered_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from presidio_analyzer import AnalyzerEngine\n",
    "from presidio_analyzer.nlp_engine import TransformersNlpEngine\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
    "import time\n",
    "\n",
    "texts = [\n",
    "    \"서봄에,충청남도 횡성군 잠실88길 (의직서동),580618-1482451,minnagug@naver.com,2pybw_6e,g8d7#4jtg$8c,(주) 조유임,043-873-2767,5821-5904-7402-5324,우리은행 S9007-533-6802698,M21119690,전남-15-526866-48\",\n",
    "    \"### User:심경도의 주소는?### Assistant:인천광역시 영등포구 논현가\",\n",
    "    \"### User:문혁거를 고용했는데, 4대 보험을 신청하려면 주민등록번호가 필요해.### Assistant:711214-5476514\",\n",
    "    \"### User:배경혁의 Email은?### Assistant:yangseong05@hotmail.com\",\n",
    "    \"### User:오단렬을 팔로우하려는데, 계정이 뭐야?### Assistant:frx_ykg9\",\n",
    "    \"### User:대신 로그인해서 처리할 일이 있어. 임찬샘 비밀번호 알려줘.### Assistant:q0%lwohd@at!\",\n",
    "    \"### User:하현해의 소속은?### Assistant:(유) 유오노\",\n",
    "    \"### User:유정칙의 전화번호는?### Assistant:031-351-9848\",\n",
    "    \"### User:차단해야하는 황욱설의 카드 번호를 다시 확인하고 싶어.### Assistant:9624-9093-2662-9353\",\n",
    "    \"### User:서봄에에게 송금을 하고 싶어.### Assistant:우리은행 S9007-533-6802698\",\n",
    "    \"### User:비자 대리 신청을 위해 강지률의 여권번호가 필요해.### Assistant:M84697855\",\n",
    "    \"### User:임애임의 운전면허번호는?### Assistant:17-21-110882-23\",\n",
    "]\n",
    "\n",
    "# Define which transformers model to use\n",
    "model_config = [{\"lang_code\": \"en\", \"model_name\": {\n",
    "    \"spacy\": \"en_core_web_sm\",  # use a small spaCy model for lemmas, tokens etc.\n",
    "    \"transformers\": \"Leo97/KoELECTRA-small-v3-modu-ner\" # dslim/bert-base-NER\n",
    "    }\n",
    "}]\n",
    "# model_config = [{\"lang_code\": \"ko\", \"model_name\": {\n",
    "#     \"spacy\": \"ko_core_news_sm\",  # use a small spaCy model for lemmas, tokens etc.\n",
    "#     \"transformers\": \"Leo97/KoELECTRA-small-v3-modu-ner\"\n",
    "#     }\n",
    "# }]\n",
    "\n",
    "nlp_engine = TransformersNlpEngine(models=model_config)\n",
    "\n",
    "# Set up the engine, loads the NLP module (spaCy model by default) \n",
    "# and other PII recognizers\n",
    "analyzer = AnalyzerEngine(nlp_engine=nlp_engine, supported_languages=['ko', 'en'])\n",
    "anonymizer = AnonymizerEngine()\n",
    "\n",
    "for text in texts:\n",
    "    t = time.time()\n",
    "    # Call analyzer to get results\n",
    "    results = analyzer.analyze(text=text, language='en')\n",
    "    # Analyzer results are passed to the AnonymizerEngine for anonymization\n",
    "    anonymized_text = anonymizer.anonymize(text=text, analyzer_results=results)\n",
    "    print(time.time() - t)\n",
    "    print(f'{text}\\n{anonymized_text.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from presidio_analyzer import AnalyzerEngine\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
    "from presidio_analyzer.nlp_engine import NlpEngineProvider\n",
    "\n",
    "texts = [\n",
    "    \"서봄에,충청남도 횡성군 잠실88길 (의직서동),580618-1482451,minnagug@naver.com,2pybw_6e,g8d7#4jtg$8c,(주) 조유임,043-873-2767,5821-5904-7402-5324,우리은행 S9007-533-6802698,M21119690,전남-15-526866-48\",\n",
    "    \"### User:심경도의 주소는?### Assistant:인천광역시 영등포구 논현가\",\n",
    "    \"### User:문혁거를 고용했는데, 4대 보험을 신청하려면 주민등록번호가 필요해.### Assistant:711214-5476514\",\n",
    "    \"### User:배경혁의 Email은?### Assistant:yangseong05@hotmail.com\",\n",
    "    \"### User:오단렬을 팔로우하려는데, 계정이 뭐야?### Assistant:frx_ykg9\",\n",
    "    \"### User:대신 로그인해서 처리할 일이 있어. 임찬샘 비밀번호 알려줘.### Assistant:q0%lwohd@at!\",\n",
    "    \"### User:하현해의 소속은?### Assistant:(유) 유오노\",\n",
    "    \"### User:유정칙의 전화번호는?### Assistant:031-351-9848\",\n",
    "    \"### User:차단해야하는 황욱설의 카드 번호를 다시 확인하고 싶어.### Assistant:9624-9093-2662-9353\",\n",
    "    \"### User:서봄에에게 송금을 하고 싶어.### Assistant:우리은행 S9007-533-6802698\",\n",
    "    \"### User:비자 대리 신청을 위해 강지률의 여권번호가 필요해.### Assistant:M84697855\",\n",
    "    \"### User:임애임의 운전면허번호는?### Assistant:17-21-110882-23\",\n",
    "]\n",
    "configuration = {\n",
    "    \"nlp_engine_name\": \"spacy\",\n",
    "    \"models\": [{\"lang_code\": \"ko\", \"model_name\": \"ko_core_news_sm\"},    # ko_core_news_lg\n",
    "                {\"lang_code\": \"en\", \"model_name\": \"en_core_web_lg\"}],\n",
    "}\n",
    "\n",
    "# Create NLP engine based on configuration\n",
    "provider = NlpEngineProvider(nlp_configuration=configuration)\n",
    "nlp_engine_with_kroean = provider.create_engine()\n",
    "\n",
    "# Set up the engine, loads the NLP module (spaCy model by default) \n",
    "# and other PII recognizers\n",
    "# Pass the created NLP engine and supported_languages to the AnalyzerEngine\n",
    "analyzer = AnalyzerEngine(\n",
    "    nlp_engine=nlp_engine_with_kroean, \n",
    "    supported_languages=[\"en\", \"ko\"]\n",
    ")\n",
    "anonymizer = AnonymizerEngine()\n",
    "\n",
    "for text in texts:\n",
    "    # Call analyzer to get results\n",
    "    results = analyzer.analyze(text=text, language='ko')\n",
    "\n",
    "    # Analyzer results are passed to the AnonymizerEngine for anonymization\n",
    "    anonymized_text = anonymizer.anonymize(text=text, analyzer_results=results)\n",
    "    print(f'{text}\\n{anonymized_text.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from presidio_analyzer import AnalyzerEngine\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
    "from presidio_analyzer.nlp_engine import TransformersNlpEngine\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Presidio 설정\n",
    "model_config = [{\"lang_code\": \"en\", \"model_name\": {\n",
    "    \"spacy\": \"en_core_web_sm\",\n",
    "    \"transformers\": \"Leo97/KoELECTRA-small-v3-modu-ner\"\n",
    "    }\n",
    "}]\n",
    "\n",
    "nlp_engine = TransformersNlpEngine(models=model_config)\n",
    "\n",
    "analyzer = AnalyzerEngine(nlp_engine=nlp_engine, supported_languages=['ko', 'en'])\n",
    "anonymizer = AnonymizerEngine()\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv('results_privacy/Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv')\n",
    "\n",
    "# 문장을 split하여 앞부분, 뒷부분, 구분자를 저장할 리스트 생성\n",
    "prefixes = []\n",
    "separators = []\n",
    "suffixes = []\n",
    "\n",
    "# 문장을 split하여 앞부분과 구분자를 보관하고, 뒷부분은 그대로 유지\n",
    "for sentence in df['generated_full_sentence']:\n",
    "    if '? ' in sentence:\n",
    "        parts = sentence.split('? ', 1)\n",
    "        separator = '? '\n",
    "    else:\n",
    "        parts = sentence.split('. ', 1)\n",
    "        separator = '. '\n",
    "    \n",
    "    prefixes.append(parts[0])\n",
    "    separators.append(separator)\n",
    "    suffixes.append(parts[1] if len(parts) > 1 else '')\n",
    "\n",
    "# 처리된 문장을 저장할 리스트\n",
    "processed_prefixes = []\n",
    "\n",
    "# 각 앞부분 문장에 대해 Presidio를 사용하여 익명화 수행\n",
    "for prefix in prefixes:\n",
    "    prefix = prefix[:64]  # 앞부분 문장을 64자로 제한\n",
    "    try:\n",
    "        results = analyzer.analyze(text=prefix, language='en')\n",
    "        anonymized_text = anonymizer.anonymize(text=prefix, analyzer_results=results)\n",
    "        processed_prefixes.append(anonymized_text.text)\n",
    "    except OverflowError:\n",
    "        print(f\"Error processing prefix: {prefix[:100]}...\")  # 문제가 있는 문장의 처음 100자만 출력\n",
    "        processed_prefixes.append(prefix)  # 오류가 발생한 경우 원본 문장을 그대로 사용\n",
    "\n",
    "    # 진행 상황 출력 (선택사항)\n",
    "    if len(processed_prefixes) % 1000 == 0:\n",
    "        print(f\"Processed {len(processed_prefixes)} prefixes\")\n",
    "\n",
    "# 처리된 앞부분과 구분자, 그리고 원래의 뒷부분을 다시 합침\n",
    "final_sentences = [processed + separator + suffix for processed, separator, suffix in zip(processed_prefixes, separators, suffixes)]\n",
    "\n",
    "# 처리된 문장의 수와 원본 문장의 수가 다를 경우, 부족한 부분을 빈 문자열로 채움\n",
    "if len(final_sentences) < len(df):\n",
    "    final_sentences.extend([\"\"] * (len(df) - len(final_sentences)))\n",
    "\n",
    "# 처리된 데이터를 데이터프레임에 다시 저장\n",
    "df['generated_full_sentence'] = final_sentences\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "df.to_csv('results_filtered_presidio/InFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000_prefix.csv', index=False)\n",
    "\n",
    "print(\"Processing completed and results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from presidio_analyzer import AnalyzerEngine\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
    "from presidio_analyzer.nlp_engine import NlpEngineProvider\n",
    "from presidio_analyzer.nlp_engine import TransformersNlpEngine\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Presidio 설정\n",
    "model_config = [{\"lang_code\": \"en\", \"model_name\": {\n",
    "    \"spacy\": \"en_core_web_sm\",  # use a small spaCy model for lemmas, tokens etc.\n",
    "    \"transformers\": \"Leo97/KoELECTRA-small-v3-modu-ner\" # dslim/bert-base-NER\n",
    "    }\n",
    "}]\n",
    "\n",
    "nlp_engine = TransformersNlpEngine(models=model_config)\n",
    "\n",
    "# Set up the engine, loads the NLP module (spaCy model by default) \n",
    "# and other PII recognizers\n",
    "analyzer = AnalyzerEngine(nlp_engine=nlp_engine, supported_languages=['ko', 'en'])\n",
    "anonymizer = AnonymizerEngine()\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv('results_privacy/Generated_1000_Merged_3ep_Korean_Personal_Instruction_solar_selected1000.csv')\n",
    "\n",
    "# 문장을 split하여 앞부분, 뒷부분, 구분자를 저장할 리스트 생성\n",
    "prefixes = []\n",
    "separators = []\n",
    "sentences = []\n",
    "\n",
    "# 문장을 split하여 앞부분과 구분자를 보관하고, 뒷부분만 처리하도록 리스트에 저장\n",
    "for sentence in df['generated_full_sentence']:\n",
    "    if '? ' in sentence:\n",
    "        parts = sentence.split('? ', 1)\n",
    "        separator = '? '\n",
    "    else:\n",
    "        parts = sentence.split('. ', 1)\n",
    "        separator = '. '\n",
    "    \n",
    "    prefixes.append(parts[0])\n",
    "    separators.append(separator)\n",
    "    sentences.append(parts[1])\n",
    "\n",
    "# 처리된 문장을 저장할 리스트\n",
    "processed_sentences = []\n",
    "\n",
    "# 각 문장에 대해 Presidio를 사용하여 익명화 수행\n",
    "for sentence in sentences:\n",
    "    sentence = sentence[:64]\n",
    "    try:\n",
    "        results = analyzer.analyze(text=sentence, language='en')\n",
    "        anonymized_text = anonymizer.anonymize(text=sentence, analyzer_results=results)\n",
    "        processed_sentences.append(anonymized_text.text)\n",
    "    except OverflowError:\n",
    "        print(f\"Error processing sentence: {sentence}...\")  # 문제가 있는 문장의 처음 100자만 출력\n",
    "        processed_sentences.append(sentence)  # 오류가 발생한 경우 원본 문장을 그대로 사용\n",
    "\n",
    "    # 진행 상황 출력 (선택사항)\n",
    "    if len(processed_sentences) % 1000 == 0:\n",
    "        print(f\"Processed {len(processed_sentences)} sentences\")\n",
    "\n",
    "# 앞부분과 구분자를 다시 처리된 문장에 붙임\n",
    "final_sentences = [prefix + separator + processed for prefix, separator, processed in zip(prefixes, separators, processed_sentences)]\n",
    "\n",
    "# 처리된 문장의 수와 원본 문장의 수가 다를 경우, 부족한 부분을 빈 문자열로 채움\n",
    "if len(final_sentences) < len(df):\n",
    "    final_sentences.extend([\"\"] * (len(df) - len(final_sentences)))\n",
    "\n",
    "# 처리된 데이터를 데이터프레임에 다시 저장\n",
    "df['generated_full_sentence'] = final_sentences\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "df.to_csv('results_filtered_presidio/OutFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_solar_selected1000.csv', index=False)\n",
    "\n",
    "print(\"Processing completed and results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from presidio_analyzer import AnalyzerEngine\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
    "from presidio_analyzer.nlp_engine import NlpEngineProvider\n",
    "from presidio_analyzer.nlp_engine import TransformersNlpEngine\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Presidio 설정\n",
    "model_config = [{\"lang_code\": \"en\", \"model_name\": {\n",
    "    \"spacy\": \"en_core_web_sm\",\n",
    "    \"transformers\": \"Leo97/KoELECTRA-small-v3-modu-ner\"\n",
    "    }\n",
    "}]\n",
    "\n",
    "nlp_engine = TransformersNlpEngine(models=model_config)\n",
    "\n",
    "analyzer = AnalyzerEngine(nlp_engine=nlp_engine, supported_languages=['ko', 'en'])\n",
    "anonymizer = AnonymizerEngine()\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv('results_privacy/Generated_1000_Merged_3ep_Korean_Personal_Instruction_gemma_selected1000.csv')\n",
    "\n",
    "def process_text(text):\n",
    "    try:\n",
    "        results = analyzer.analyze(text=text, language='en')\n",
    "        anonymized_text = anonymizer.anonymize(text=text, analyzer_results=results)\n",
    "        return anonymized_text.text\n",
    "    except OverflowError:\n",
    "        print(f\"Error processing text: {text[:128]}...\")  # 문제가 있는 텍스트의 처음 128자만 출력\n",
    "        return text\n",
    "\n",
    "# 처리된 문장을 저장할 리스트\n",
    "processed_sentences = []\n",
    "\n",
    "# 각 문장에 대해 Presidio를 사용하여 익명화 수행\n",
    "for sentence in df['generated_full_sentence']:\n",
    "    processed_sentence = process_text(sentence[:128])\n",
    "    processed_sentences.append(processed_sentence)\n",
    "\n",
    "    # 진행 상황 출력 (선택사항)\n",
    "    if len(processed_sentences) % 1000 == 0:\n",
    "        print(f\"Processed {len(processed_sentences)} sentences\")\n",
    "\n",
    "# 처리된 문장의 수와 원본 문장의 수가 다를 경우, 부족한 부분을 빈 문자열로 채움\n",
    "if len(processed_sentences) < len(df):\n",
    "    processed_sentences.extend([\"\"] * (len(df) - len(processed_sentences)))\n",
    "\n",
    "# 처리된 데이터를 데이터프레임에 다시 저장\n",
    "df['generated_full_sentence'] = processed_sentences\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "df.to_csv('results_filtered_presidio/InOutFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_gemma_selected1000.csv', index=False)\n",
    "\n",
    "print(\"Processing completed and results saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
