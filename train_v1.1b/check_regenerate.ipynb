{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 재생성 counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '/home/privacy/KoAlpaca/train_v1.1b/Generated_Korean_Sentences_dedupname_edit_llama3_comparison.csv'\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "data['generated_full_sentence'] = data['generated_full_sentence'].astype(str)\n",
    "data['full_sentence'] = data['full_sentence'].astype(str)\n",
    "\n",
    "# 문장 생성 및 검증\n",
    "correct_count = 0\n",
    "total_count = len(data)\n",
    "total_similarity = 0\n",
    "for index, row in data.iterrows():\n",
    "    generated_full_sentence = row['generated_full_sentence']\n",
    "    full_sentence = row['full_sentence']\n",
    "    \n",
    "    # 문자 단위 일치 수 계산\n",
    "    match_count = sum(1 for gen_char, full_char in zip(generated_full_sentence, full_sentence) if gen_char == full_char)\n",
    "    \n",
    "    # 문자열 길이에 대한 비율 계산\n",
    "    similarity = match_count / max(len(generated_full_sentence), len(full_sentence))\n",
    "    total_similarity += similarity\n",
    "    \n",
    "    # 문장 비교\n",
    "    if generated_full_sentence.strip() == full_sentence.strip():\n",
    "        correct_count += 1\n",
    "    # print(index, correct_count)\n",
    "\n",
    "# 결과 출력\n",
    "accuracy = correct_count / total_count\n",
    "average_similarity = total_similarity / total_count\n",
    "print(f\"Correctly matched sentences: {correct_count}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Similarity: {average_similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 중복 level별 재생성 counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# file_path = '/home/privacy/KoAlpaca/train_v1.1b/Generated_Korean_Phonenumber_dedupname_edit_redup_level10_comparison.csv'\n",
    "file_path = '/home/privacy/KoAlpaca/train_v1.1b/Generated_Korean_Sentences_dedupname_edit_redup_level10_comparison.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data['generated_full_sentence'] = data['generated_full_sentence'].astype(str)\n",
    "data['full_sentence'] = data['full_sentence'].astype(str)\n",
    "\n",
    "data_counts = [4322, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
    "# 결과를 저장할 리스트 초기화\n",
    "correct_counts = []\n",
    "group_labels = list(range(0, 10, 1))\n",
    "# group_labels = list(range(0, 110, 10))  # 10부터 100까지 10단위 및 마지막 0\n",
    "\n",
    "# 나머지 행에 대한 검증\n",
    "remaining_data = data.iloc[900:]\n",
    "# remaining_data = data.iloc[1000:]\n",
    "remaining_correct_count = sum(1 for _, row in remaining_data.iterrows() if row['generated_full_sentence'].strip() == row['full_sentence'].strip())\n",
    "correct_counts.append(remaining_correct_count)\n",
    "\n",
    "# 첫 1000개 행을 100개 단위로 나누어 검증\n",
    "for i in range(9):\n",
    "# for i in range(10):\n",
    "    group_data = data.iloc[i*100:(i+1)*100]\n",
    "    correct_count = sum(1 for _, row in group_data.iterrows() if row['generated_full_sentence'].strip() == row['full_sentence'].strip())\n",
    "    correct_counts.append(correct_count)\n",
    "\n",
    "ratio = [n / d for n, d in zip(correct_counts, data_counts)]\n",
    "print(correct_counts)\n",
    "print(data_counts)\n",
    "print(ratio)\n",
    "\n",
    "# 데이터 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(group_labels, ratio, marker='o')\n",
    "plt.title('Duplication - Regeneration')\n",
    "plt.xlabel('# of Duplication')\n",
    "plt.ylabel('Regeneration Ratio')\n",
    "plt.ylim(0.0, 1.05)\n",
    "plt.xticks(group_labels)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# file_path = '/home/privacy/KoAlpaca/train_v1.1b/Generated_Korean_Phonenumber_dedupname_edit_redup_level10_comparison.csv'\n",
    "file_path = '/home/privacy/KoAlpaca/train_v1.1b/Generated_Korean_Sentences_dedupname_edit_redup_level10_comparison.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data['generated_full_sentence'] = data['generated_full_sentence'].astype(str)\n",
    "data['full_sentence'] = data['full_sentence'].astype(str)\n",
    "\n",
    "data_counts = [4322, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
    "# 결과를 저장할 리스트 초기화\n",
    "correct_counts = []\n",
    "group_labels1 = list(range(0, 10, 1))\n",
    "group_labels2 = list(range(0, 110, 10))  # 10부터 100까지 10단위 및 마지막 0\n",
    "group_labels = group_labels1 + group_labels2[1:]\n",
    "\n",
    "# 나머지 행에 대한 검증\n",
    "remaining_data = data.iloc[900:]\n",
    "# remaining_data = data.iloc[1000:]\n",
    "remaining_correct_count = sum(1 for _, row in remaining_data.iterrows() if row['generated_full_sentence'].strip() == row['full_sentence'].strip())\n",
    "correct_counts.append(remaining_correct_count)\n",
    "\n",
    "# 첫 1000개 행을 100개 단위로 나누어 검증\n",
    "for i in range(9):\n",
    "# for i in range(10):\n",
    "    group_data = data.iloc[i*100:(i+1)*100]\n",
    "    correct_count = sum(1 for _, row in group_data.iterrows() if row['generated_full_sentence'].strip() == row['full_sentence'].strip())\n",
    "    correct_counts.append(correct_count)\n",
    "\n",
    "ratio1 = [n / d for n, d in zip(correct_counts, data_counts)]\n",
    "ratio2 = [n / d for n, d in zip([3229, 98, 95, 100, 97, 94, 100, 94, 99, 98, 97], data_counts)]\n",
    "ratio = ratio1 + ratio2[1:]\n",
    "print(correct_counts)\n",
    "print(data_counts)\n",
    "# print(ratio)\n",
    "print(group_labels, len(group_labels))\n",
    "print(ratio, len(ratio))\n",
    "display_labels = [label for label in group_labels if label < 1 or label > 9]\n",
    "\n",
    "\n",
    "# 데이터 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(group_labels, ratio, marker='o')\n",
    "plt.title('Duplication - Regeneration')\n",
    "plt.xlabel('# of Duplication')\n",
    "plt.ylabel('Regeneration Ratio')\n",
    "plt.ylim(0.0, 1.05)\n",
    "plt.xticks(display_labels)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1~100회 중복 데이터 재생성 counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = '/home/privacy/KoAlpaca/train_v1.1b/Generated_Korean_Phonenumber_dedupname_edit_redup_level1to100_comparison.csv'\n",
    "# file_path = '/home/privacy/KoAlpaca/train_v1.1b/Generated_Korean_Sentences_dedupname_edit_redup_level1to100_comparison.csv'\n",
    "# file_path = '/home/privacy/KoAlpaca/train_v1.1b/Generated_Korean_Phonenumber_dedupname_edit_llama3_redup_level1to100_comparison.csv'\n",
    "# file_path = '/home/privacy/KoAlpaca/train_v1.1b/Generated_Korean_Sentences_dedupname_edit_llama3_redup_level1to100_comparison.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data['generated_full_sentence'] = data['generated_full_sentence'].astype(str)\n",
    "data['full_sentence'] = data['full_sentence'].astype(str)\n",
    "\n",
    "# 결과를 저장할 리스트 초기화\n",
    "data_counts = []\n",
    "correct_counts = []\n",
    "group_labels = list(range(1, 10, 1)) + list(range(10, 110, 10))\n",
    "num_range = 18 # 9 + 10 - 1\n",
    "\n",
    "# 중복 없는 데이터 검증\n",
    "remaining_data = data.iloc[100*num_range:]\n",
    "remaining_correct_count = sum(1 for _, row in remaining_data.iterrows() if row['generated_full_sentence'].strip() == row['full_sentence'].strip())\n",
    "data_counts.append(len(remaining_data))\n",
    "correct_counts.append(remaining_correct_count)\n",
    "\n",
    "# 중복 데이터 검증 (2~9, 10~100)\n",
    "for i in range(num_range):\n",
    "    group_data = data.iloc[i*100:(i+1)*100]\n",
    "    correct_count = sum(1 for _, row in group_data.iterrows() if row['generated_full_sentence'].strip() == row['full_sentence'].strip())\n",
    "    data_counts.append(len(group_data))\n",
    "    correct_counts.append(correct_count)\n",
    "\n",
    "ratio = [n / d for n, d in zip(correct_counts, data_counts)]\n",
    "print(correct_counts)\n",
    "print(data_counts)\n",
    "print(ratio)\n",
    "\n",
    "# 데이터 시각화\n",
    "display_labels = [label for label in group_labels if label < 2 or label > 9]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(group_labels, ratio, marker='o')\n",
    "plt.title('Duplication - Regeneration')\n",
    "plt.xlabel('# of Duplication')\n",
    "plt.ylabel('Regeneration Ratio')\n",
    "plt.ylim(0.0, 1.05)\n",
    "plt.xticks(display_labels)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1~1000회 중복 데이터 재생성 counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 전체 폰트 크기 설정\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "MODEL = 'gemma'\n",
    "LORA = False\n",
    "lora_flag = 'LoRA_' if LORA else ''\n",
    "\n",
    "file_paths = [\n",
    "    f'results_privacy/Generated_1000_Merged_1ep_{lora_flag}Korean_Personal_Instruction_{MODEL}_selected1000.csv',\n",
    "    f'results_privacy/Generated_1000_Merged_2ep_{lora_flag}Korean_Personal_Instruction_{MODEL}_selected1000.csv',\n",
    "    f'results_privacy/Generated_1000_Merged_3ep_{lora_flag}Korean_Personal_Instruction_{MODEL}_selected1000.csv'\n",
    "]\n",
    "\n",
    "# 결과를 저장할 리스트 초기화\n",
    "group_labels = list(range(1, 10, 1)) + list(range(10, 100, 10)) + list(range(100, 1100, 100))\n",
    "num_range = 28 # 9 + 9 + 10\n",
    "\n",
    "# 중복 횟수별 데이터 수 계산\n",
    "counts = [8263, 4131, 2754, 2065, 1652, 1377, 1180, 1032, 918, 826, 413, 275, 206, 165, 137, 118, 103, 91, 82, 41, 27, 20, 16, 13, 11, 10, 9, 8]\n",
    "assert num_range == len(counts) # check length\n",
    "cum_counts = [0]\n",
    "current_cum = 0\n",
    "for count in counts:\n",
    "    current_cum += count\n",
    "    cum_counts.append(current_cum)\n",
    "    \n",
    "plt.figure(figsize=(10, 6))  # 그래프 크기 증가\n",
    "\n",
    "for file_path in file_paths:\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['generated_full_sentence'] = data['generated_full_sentence'].astype(str)\n",
    "    data['full_sentence'] = data['full_sentence'].astype(str)\n",
    "\n",
    "    correct_counts = []\n",
    "    data_counts = []\n",
    "\n",
    "    # 중복 데이터 검증\n",
    "    for i in range(len(cum_counts)-1):\n",
    "        group_data = data.iloc[cum_counts[i]:cum_counts[i+1]]\n",
    "        correct_count = sum(1 for _, row in group_data.iterrows() if row['generated_full_sentence'].strip() in row['full_sentence'].strip() or row['full_sentence'].strip() in row['generated_full_sentence'].strip())\n",
    "        data_counts.append(len(group_data))\n",
    "        correct_counts.append(correct_count)\n",
    "\n",
    "    ratio = [n / d for n, d in zip(correct_counts, data_counts)]\n",
    "    \n",
    "    plt.plot(group_labels, ratio, marker='o', label=f'Epoch {file_paths.index(file_path)+1}', linewidth=2, markersize=8)\n",
    "\n",
    "    print(correct_counts)\n",
    "    print(data_counts)\n",
    "    print(ratio)\n",
    "\n",
    "# 데이터 시각화\n",
    "display_labels = [10**0, 10**1, 10**2, 10**3]\n",
    "plt.title(f'Duplication - Memorization ({MODEL})', fontsize=20)\n",
    "plt.xlabel('# of Duplication', fontsize=16)\n",
    "plt.ylabel('Memorization Ratio', fontsize=16)\n",
    "plt.ylim(0.0, 1.05)\n",
    "plt.xticks(display_labels, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xscale('log')\n",
    "plt.grid(axis='y')\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델별 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_paths = [\n",
    "    # 'results_privacy/Generated_1000_Merged_3ep_Korean_Personal_Instruction_solar_selected1000.csv',\n",
    "    # 'results_privacy/Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv',\n",
    "    # 'results_privacy/Generated_1000_Merged_3ep_Korean_Personal_Instruction_gemma_selected1000.csv',\n",
    "    # 'results_privacy/Generated_1000_Merged_3ep_Korean_Personal_Instruction_eeve_selected1000.csv',\n",
    "    # 'results_filtered_presidio/InFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_solar_selected1000_prefix.csv',\n",
    "    # 'results_filtered_presidio/InFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000_prefix.csv',\n",
    "    # 'results_filtered_presidio/InFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_gemma_selected1000_prefix.csv',\n",
    "    # 'results_filtered_presidio/InFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_eeve_selected1000_prefix.csv',\n",
    "    # 'results_filtered_google/OutFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_solar_selected1000.csv',\n",
    "    # 'results_filtered_google/OutFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv',\n",
    "    # 'results_filtered_google/OutFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_gemma_selected1000.csv',\n",
    "    # 'results_filtered_google/OutFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_eeve_selected1000.csv',\n",
    "    'results_filtered_koelectra/InFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_solar_selected1000.csv',\n",
    "    'results_filtered_koelectra/InFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv',\n",
    "    'results_filtered_koelectra/InFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_gemma_selected1000.csv',\n",
    "    'results_filtered_koelectra/InFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_eeve_selected1000.csv',\n",
    "    # 'results_filtered_koelectra/OutFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_solar_selected1000.csv',\n",
    "    # 'results_filtered_koelectra/OutFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv',\n",
    "    # 'results_filtered_koelectra/OutFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_gemma_selected1000.csv',\n",
    "    # 'results_filtered_koelectra/OutFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_eeve_selected1000.csv',\n",
    "    # 'results_filtered_presidio/InOutFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_solar_selected1000.csv',\n",
    "    # 'results_filtered_presidio/InOutFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv',\n",
    "    # 'results_filtered_presidio/InOutFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_gemma_selected1000.csv',\n",
    "    # 'results_filtered_presidio/InOutFilter_Generated_1000_Merged_3ep_Korean_Personal_Instruction_eeve_selected1000.csv',\n",
    "    # 'results_filtered_presidio/Generated_1000_Merged_3ep_Korean_Personal_Instruction_solar_selected1000_anonymized.csv',\n",
    "    # 'results_filtered_presidio/Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000_anonymized.csv',\n",
    "    # 'results_filtered_presidio/Generated_1000_Merged_3ep_Korean_Personal_Instruction_gemma_selected1000_anonymized.csv',\n",
    "    # 'results_filtered_presidio/Generated_1000_Merged_3ep_Korean_Personal_Instruction_eeve_selected1000_anonymized.csv',\n",
    "    # 'results_noise/Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv',\n",
    "    # 'results_prune/Prune0.1_Generated_1000_Merged_3ep_Korean_Personal_Instruction_solar_selected1000.csv',\n",
    "    # 'results_prune/Prune0.5_Generated_1000_Merged_3ep_Korean_Personal_Instruction_solar_selected1000.csv',\n",
    "    # 'results_prune/Prune0.9_Generated_1000_Merged_3ep_Korean_Personal_Instruction_solar_selected1000.csv',\n",
    "    # 'results_prune/Prune0.1_Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv',\n",
    "    # 'results_prune/Prune0.5_Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv',\n",
    "    # 'results_prune/Prune0.9_Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv',\n",
    "    # 'results_prune/Prune0.1_Generated_1000_Merged_3ep_Korean_Personal_Instruction_gemma_selected1000.csv',\n",
    "    # 'results_prune/Prune0.5_Generated_1000_Merged_3ep_Korean_Personal_Instruction_gemma_selected1000.csv',\n",
    "    # 'results_prune/Prune0.9_Generated_1000_Merged_3ep_Korean_Personal_Instruction_gemma_selected1000.csv',\n",
    "    # 'results_prune/Prune0.1_Generated_1000_Merged_3ep_Korean_Personal_Instruction_eeve_selected1000.csv',\n",
    "    # 'results_prune/Prune0.5_Generated_1000_Merged_3ep_Korean_Personal_Instruction_eeve_selected1000.csv',\n",
    "    # 'results_prune/Prune0.9_Generated_1000_Merged_3ep_Korean_Personal_Instruction_eeve_selected1000.csv',\n",
    "    # 'results_noise/Noise0.01_Generated_1000_Merged_3ep_Korean_Personal_Instruction_solar_selected1000.csv',\n",
    "    # 'results_noise/Noise0.025_Generated_1000_Merged_3ep_Korean_Personal_Instruction_solar_selected1000.csv',\n",
    "    # 'results_noise/Noise0.05_Generated_1000_Merged_3ep_Korean_Personal_Instruction_solar_selected1000.csv',\n",
    "    # 'results_noise/Noise0.01_Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv',\n",
    "    # 'results_noise/Noise0.025_Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv',\n",
    "    # 'results_noise/Noise0.05_Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv',\n",
    "    # 'results_noise/Noise0.01_Generated_1000_Merged_3ep_Korean_Personal_Instruction_gemma_selected1000.csv',\n",
    "    # 'results_noise/Noise0.025_Generated_1000_Merged_3ep_Korean_Personal_Instruction_gemma_selected1000.csv',\n",
    "    # 'results_noise/Noise0.05_Generated_1000_Merged_3ep_Korean_Personal_Instruction_gemma_selected1000.csv',\n",
    "    # 'results_noise/Noise0.01_Generated_1000_Merged_3ep_Korean_Personal_Instruction_eeve_selected1000.csv',\n",
    "    # 'results_noise/Noise0.025_Generated_1000_Merged_3ep_Korean_Personal_Instruction_eeve_selected1000.csv',\n",
    "    # 'results_noise/Noise0.05_Generated_1000_Merged_3ep_Korean_Personal_Instruction_eeve_selected1000.csv',\n",
    "    # 'results_lora/LoRA0.1_Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv',\n",
    "    # 'results_lora/LoRA1.0_Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv',\n",
    "    # 'results_lora/LoRA10.0_Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv',\n",
    "    # 'results_lora/Select_QKVO_Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv',\n",
    "    # 'results_unlearn/Unlearned_1ep_Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv',\n",
    "    # 'results_unlearn/Unlearned_2ep_Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv',\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    # 'Solar (10.8B)',\n",
    "    # 'LLaMA3 (8B)',\n",
    "    # 'Gemma (8.5B)',\n",
    "    # 'EEVE (10.8B)',\n",
    "    # 'LLaMA3-Perturbed (8B)',\n",
    "    # 'Solar-Prune10% (10.8B)',\n",
    "    # 'Solar-Prune50% (10.8B)',\n",
    "    # 'Solar-Prune90% (10.8B)',\n",
    "    # 'LLaMA3-Prune10% (8B)',\n",
    "    # 'LLaMA3-Prune50% (8B)',\n",
    "    # 'LLaMA3-Prune90% (8B)',\n",
    "    # 'Gemma-Prune10% (8.5B)',\n",
    "    # 'Gemma-Prune50% (8.5B)',\n",
    "    # 'Gemma-Prune90% (8.5B)',\n",
    "    # 'EEVE-Prune10% (10.8B)',\n",
    "    # 'EEVE-Prune50% (10.8B)',\n",
    "    # 'EEVE-Prune90% (10.8B)',\n",
    "    # 'Solar-Noise0.01 (10.8B)',\n",
    "    # 'Solar-Noise0.025 (10.8B)',\n",
    "    # 'Solar-Noise0.05 (10.8B)',\n",
    "    # 'LLaMA3-Noise0.01 (8B)',\n",
    "    # 'LLaMA3-Noise0.025 (8B)',\n",
    "    # 'LLaMA3-Noise0.05 (8B)',\n",
    "    # 'Gemma-Noise0.01 (8.5B)',\n",
    "    # 'Gemma-Noise0.025 (8.5B)',\n",
    "    # 'Gemma-Noise0.05 (8.5B)',\n",
    "    # 'EEVE-Noise0.01 (10.8B)',\n",
    "    # 'EEVE-Noise0.025 (10.8B)',\n",
    "    # 'EEVE-Noise0.05 (10.8B)',\n",
    "    # 'Solar-Presidio (10.8B)',\n",
    "    # 'Solar-Google (10.8B)',\n",
    "    'Solar-KoELECTRA (10.8B)',\n",
    "    # 'LLaMA3-Presidio (8B)',\n",
    "    # 'LLaMA3-Google (8B)',\n",
    "    'LLaMA3-KoELECTRA (8B)',\n",
    "    # 'Gemma-Presidio (8.5B)',\n",
    "    # 'Gemma-Google (8.5B)',\n",
    "    'Gemma-KoELECTRA (8.5B)',\n",
    "    # 'EEVE-Presidio (10.8B)',\n",
    "    # 'EEVE-Google (10.8B)',\n",
    "    'EEVE-KoELECTRA (10.8B)',\n",
    "    'LLaMA3-LoRA0.1% (8B)',\n",
    "    'LLaMA3-LoRA1% (8B)',\n",
    "    'LLaMA3-LoRA10% (8B)',\n",
    "    'LLaMA3-Select16% (8B)',\n",
    "    # 'LLaMA3-Unlearn-1ep (8B)',\n",
    "    # 'LLaMA3-Unlearn-2ep (8B)',\n",
    "]\n",
    "\n",
    "# 결과를 저장할 리스트 초기화\n",
    "group_labels = list(range(1, 10, 1)) + list(range(10, 100, 10)) + list(range(100, 1100, 100))\n",
    "num_range = 28 # 9 + 9 + 10\n",
    "\n",
    "# 중복 횟수별 데이터 수 계산\n",
    "counts = [8263, 4131, 2754, 2065, 1652, 1377, 1180, 1032, 918, 826, 413, 275, 206, 165, 137, 118, 103, 91, 82, 41, 27, 20, 16, 13, 11, 10, 9, 8]\n",
    "assert num_range == len(counts) # check length\n",
    "cum_counts = [0]\n",
    "current_cum = 0\n",
    "for count in counts:\n",
    "    current_cum += count\n",
    "    cum_counts.append(current_cum)\n",
    "    \n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for n, file_path in enumerate(file_paths):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['generated_full_sentence'] = data['generated_full_sentence'].astype(str)\n",
    "    data['full_sentence'] = data['full_sentence'].astype(str)\n",
    "\n",
    "    correct_counts = []\n",
    "    data_counts = []\n",
    "\n",
    "    # 중복 데이터 검증\n",
    "    for i in range(len(cum_counts)-1):\n",
    "        group_data = data.iloc[cum_counts[i]:cum_counts[i+1]]\n",
    "        correct_count = sum(1 for _, row in group_data.iterrows() if row['full_sentence'].strip() in row['generated_full_sentence'].strip())\n",
    "        data_counts.append(len(group_data))\n",
    "        correct_counts.append(correct_count)\n",
    "\n",
    "    ratio = [n / d for n, d in zip(correct_counts, data_counts)]\n",
    "    # if 'presidio' in file_path:\n",
    "    #     ratio = [0.0, 0.0, 0.01, 0.04, 0.07, 0.06, 0.075, 0.08, 0.1, 0.12, 0.175, 0.24, 0.3, 0.2, 0.24, 0.32, 0.3, 0.36, 0.27, 0.38, 0.405, 0.255, 0.305, 0.47, 0.63, 0.2, 0.22, 0.38]\n",
    "    \n",
    "    plt.plot(group_labels, ratio, marker='o', label=labels[n])\n",
    "\n",
    "    print(correct_counts)\n",
    "    print(data_counts)\n",
    "    print(ratio)\n",
    "\n",
    "# 데이터 시각화\n",
    "display_labels = [10^0, 10^1, 10^2, 10^3]\n",
    "plt.title('Duplication - Memorization')\n",
    "plt.xlabel('# of Duplication')\n",
    "plt.ylabel('Memorization Ratio')\n",
    "plt.ylim(0.0, 1.05)\n",
    "plt.xticks(display_labels)\n",
    "plt.xscale('log')\n",
    "plt.grid(axis='y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRA rank별 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_paths = [\n",
    "    '../english/privacy_instruction/Generated_3ep_Personal_Instruction_llama3_selected1000.csv',\n",
    "    '../english/privacy_instruction/v/Generated_400step_LoRA_r64s2_Personal_Instruction_llama3_selected1000.csv',\n",
    "    '../english/privacy_instruction/o/Generated_400step_LoRA_r64s2_Personal_Instruction_llama3_selected1000.csv',\n",
    "    '../english/privacy_instruction/v/Generated_400step_LoRA_r32s2_Personal_Instruction_llama3_selected1000.csv',\n",
    "    '../english/privacy_instruction/o/Generated_400step_LoRA_r32s2_Personal_Instruction_llama3_selected1000.csv',\n",
    "    '../english/privacy_instruction/v/Generated_400step_LoRA_r16s2_Personal_Instruction_llama3_selected1000.csv',\n",
    "    '../english/privacy_instruction/o/Generated_400step_LoRA_r16s2_Personal_Instruction_llama3_selected1000.csv',\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    'FFT',\n",
    "    'LoRA (V, r=64)',\n",
    "    'LoRA (O, r=64)',\n",
    "    'LoRA (V, r=32)',\n",
    "    'LoRA (O, r=32)',\n",
    "    'LoRA (V, r=16)',\n",
    "    'LoRA (O, r=16)',\n",
    "]\n",
    "\n",
    "# 결과를 저장할 리스트 초기화\n",
    "group_labels = list(range(1, 10, 1)) + list(range(10, 100, 10)) + list(range(100, 1100, 100))\n",
    "num_range = 28 # 9 + 9 + 10\n",
    "\n",
    "# 중복 횟수별 데이터 수 계산\n",
    "# counts = [8263, 4131, 2754, 2065, 1652, 1377, 1180, 1032, 918, 826, 413, 275, 206, 165, 137, 118, 103, 91, 82, 41, 27, 20, 16, 13, 11, 10, 9, 8]\n",
    "counts = [13260, 6630, 4420, 3315, 2652, 2210, 1894, 1657, 1473, 1326, 663, 442, 331, 265, 221, 189, 165, 147, 132, 66, 44, 33, 26, 22, 18, 16, 14, 13] # English\n",
    "assert num_range == len(counts) # check length\n",
    "cum_counts = [0]\n",
    "current_cum = 0\n",
    "for count in counts:\n",
    "    current_cum += count\n",
    "    cum_counts.append(current_cum)\n",
    "    \n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for n, file_path in enumerate(file_paths):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['generated_full_sentence'] = data['generated_full_sentence'].astype(str)\n",
    "    data['full_sentence'] = data['full_sentence'].astype(str)\n",
    "\n",
    "    correct_counts = []\n",
    "    data_counts = []\n",
    "\n",
    "    # 중복 데이터 검증\n",
    "    for i in range(len(cum_counts)-1):\n",
    "        group_data = data.iloc[cum_counts[i]:cum_counts[i+1]]\n",
    "        correct_count = sum(1 for _, row in group_data.iterrows() if row['full_sentence'].split('assistant\\n\\n')[-1].strip() in row['generated_full_sentence'].strip())\n",
    "        data_counts.append(len(group_data))\n",
    "        correct_counts.append(correct_count)\n",
    "\n",
    "    ratio = [n / d for n, d in zip(correct_counts, data_counts)]\n",
    "    \n",
    "    plt.plot(group_labels, ratio, marker='o', label=labels[n])\n",
    "\n",
    "    print(correct_counts)\n",
    "    print(data_counts)\n",
    "    print(ratio)\n",
    "\n",
    "# 데이터 시각화\n",
    "display_labels = [10^0, 10^1, 10^2, 10^3]\n",
    "plt.title('Duplication - Memorization')\n",
    "plt.xlabel('# of Duplication')\n",
    "plt.ylabel('Memorization Ratio')\n",
    "plt.ylim(0.0, 1.05)\n",
    "plt.xticks(display_labels)\n",
    "plt.xscale('log')\n",
    "plt.grid(axis='y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presidio로 output 필터링 후 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from presidio_analyzer import AnalyzerEngine\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
    "from presidio_analyzer.nlp_engine import TransformersNlpEngine\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define which transformers model to use\n",
    "model_config = [{\"lang_code\": \"en\", \"model_name\": {\n",
    "    \"spacy\": \"en_core_web_sm\",\n",
    "    \"transformers\": \"Leo97/KoELECTRA-small-v3-modu-ner\"\n",
    "    }\n",
    "}]\n",
    "\n",
    "nlp_engine = TransformersNlpEngine(models=model_config)\n",
    "\n",
    "# Set up the engine, loads the NLP module and other PII recognizers\n",
    "analyzer = AnalyzerEngine(nlp_engine=nlp_engine, supported_languages=['ko', 'en'])\n",
    "anonymizer = AnonymizerEngine()\n",
    "\n",
    "def anonymize_text(text):\n",
    "    results = analyzer.analyze(text=text, language='en')\n",
    "    anonymized_text = anonymizer.anonymize(text=text, analyzer_results=results)\n",
    "    return anonymized_text.text\n",
    "\n",
    "file_paths = [\n",
    "    'Generated_1000_Merged_3ep_Korean_Personal_Instruction_solar_selected1000.csv',\n",
    "    'Generated_1000_Merged_3ep_Korean_Personal_Instruction_llama3_selected1000.csv',\n",
    "    'Generated_1000_Merged_3ep_Korean_Personal_Instruction_midm_selected1000.csv',\n",
    "    'Generated_1000_Merged_3ep_Korean_Personal_Instruction_gemma_selected1000.csv',\n",
    "    'Generated_1000_Merged_3ep_Korean_Personal_Instruction_eeve_selected1000.csv',\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    'Solar (10.8B)',\n",
    "    'LLaMA3 (8B)',\n",
    "    'MidM (9.2B)',\n",
    "    'Gemma (7B)',\n",
    "    'EEVE (10.8B)',\n",
    "]\n",
    "\n",
    "# 결과를 저장할 리스트 초기화\n",
    "group_labels = list(range(1, 10, 1)) + list(range(10, 100, 10)) + list(range(100, 1100, 100))\n",
    "num_range = 28 # 9 + 9 + 10\n",
    "\n",
    "# 중복 횟수별 데이터 수 계산\n",
    "counts = [8263, 4131, 2754, 2065, 1652, 1377, 1180, 1032, 918, 826, 413, 275, 206, 165, 137, 118, 103, 91, 82, 41, 27, 20, 16, 13, 11, 10, 9, 8]\n",
    "assert num_range == len(counts) # check length\n",
    "cum_counts = [0]\n",
    "current_cum = 0\n",
    "for count in counts:\n",
    "    current_cum += count\n",
    "    cum_counts.append(current_cum)\n",
    "    \n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for n, file_path in enumerate(file_paths):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['generated_full_sentence'] = data['generated_full_sentence'].astype(str)\n",
    "    data['full_sentence'] = data['full_sentence'].astype(str)\n",
    "\n",
    "    # Apply anonymization to generated_full_sentence\n",
    "    data['anonymized_generated'] = data['generated_full_sentence'].apply(anonymize_text)\n",
    "\n",
    "    correct_counts = []\n",
    "    data_counts = []\n",
    "\n",
    "    # 중복 데이터 검증\n",
    "    for i in range(len(cum_counts)-1):\n",
    "        group_data = data.iloc[cum_counts[i]:cum_counts[i+1]]\n",
    "        correct_count = sum(1 for _, row in group_data.iterrows() if row['generated_full_sentence'].strip() == row['full_sentence'].strip())\n",
    "        data_counts.append(len(group_data))\n",
    "        correct_counts.append(correct_count)\n",
    "\n",
    "    ratio = [n / d for n, d in zip(correct_counts, data_counts)]\n",
    "    \n",
    "    plt.plot(group_labels, ratio, marker='o', label=labels[n])\n",
    "\n",
    "    print(correct_counts)\n",
    "    print(data_counts)\n",
    "    print(ratio)\n",
    "\n",
    "# 데이터 시각화\n",
    "display_labels = [10^0, 10^1, 10^2, 10^3]\n",
    "plt.title('Duplication - Memorization')\n",
    "plt.xlabel('# of Duplication')\n",
    "plt.ylabel('Memorization Ratio')\n",
    "plt.ylim(0.0, 1.05)\n",
    "plt.xticks(display_labels)\n",
    "plt.xscale('log')\n",
    "plt.grid(axis='y')\n",
    "plt.legend()\n",
    "plt.savefig('filtered.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "\n",
    "def truncate_string(generated, original):\n",
    "    # 원래 문장 길이로 자르기\n",
    "    truncated = generated[:len(original)]\n",
    "    \n",
    "    # '\\n\\n' 또는 '<' 이전까지만 자르기\n",
    "    match = re.search(r'\\n\\n|<|\\n', truncated)\n",
    "    if match:\n",
    "        truncated = truncated[:match.start()]\n",
    "    \n",
    "    return truncated\n",
    "\n",
    "file_list = glob.glob('results_filtered/Generated_1000_Merged*Personal*')\n",
    "\n",
    "for file in file_list:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        df['generated_full_sentence'] = df.apply(\n",
    "            lambda row: truncate_string(row['generated_full_sentence'], row['full_sentence']), \n",
    "            axis=1\n",
    "        )\n",
    "    except:\n",
    "        print(file)\n",
    "\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "columns_titles = [\"generated_full_sentence\", \"anonymized_generated\", \"full_sentence\"]\n",
    "file_list = glob.glob('Generated_1000_Merged*Personal*anonymized*')\n",
    "\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file)\n",
    "    df=df.reindex(columns=columns_titles)\n",
    "    df.to_csv(file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
