{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4,5,6,7'\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def load_model(model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\", trust_remote_code=True)\n",
    "    return tokenizer, model\n",
    "\n",
    "def get_projection_weights(model, block_indices):\n",
    "    proj_weights = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        for block_idx in block_indices:\n",
    "            if f'layers.{block_idx}.' in name and any(proj in name for proj in ['q_proj', 'k_proj', 'v_proj', 'o_proj']):\n",
    "                proj_weights[name] = param.detach()\n",
    "    return proj_weights\n",
    "\n",
    "def get_block_weights(model, block_indices):\n",
    "    block_weights = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        for block_idx in block_indices:\n",
    "            if f'layers.{block_idx}.' in name:\n",
    "                block_weights[name] = param.detach()\n",
    "    return block_weights\n",
    "\n",
    "def flatten_weights(weights):\n",
    "    flattened = []\n",
    "    for w in weights.values():\n",
    "        flattened.append(w.flatten().cpu())\n",
    "    return torch.cat(flattened)\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    return torch.dot(v1, v2) / (torch.linalg.vector_norm(v1) * torch.linalg.vector_norm(v2))\n",
    "\n",
    "def visualize_weight_changes(base_weights, full_ft_weights, lora_weights, block_indices, reference_point='base'):\n",
    "    base_flat = flatten_weights(base_weights)\n",
    "    full_ft_flat = flatten_weights(full_ft_weights)\n",
    "    lora_flat = flatten_weights(lora_weights)\n",
    "\n",
    "    if reference_point == 'base':\n",
    "        full_ft_change = full_ft_flat - base_flat\n",
    "        lora_change = lora_flat - base_flat\n",
    "\n",
    "        # Calculate cosine similarity and angle\n",
    "        cos_sim = cosine_similarity(full_ft_change, lora_change)\n",
    "        angle = torch.acos(cos_sim) * 180 / np.pi\n",
    "\n",
    "        # Calculate magnitudes\n",
    "        full_ft_mag = torch.linalg.vector_norm(full_ft_change)\n",
    "        lora_mag = torch.linalg.vector_norm(lora_change)\n",
    "\n",
    "        # Calculate vector components\n",
    "        full_ft_x = full_ft_mag  # Full Fine-tuning vector along x-axis\n",
    "        full_ft_y = 0\n",
    "        lora_x = lora_mag * torch.cos(torch.tensor(angle * np.pi / 180))\n",
    "        lora_y = lora_mag * torch.sin(torch.tensor(angle * np.pi / 180))\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.quiver(0, 0, full_ft_x.item(), full_ft_y, angles='xy', scale_units='xy', scale=1, color='b', label='Full Fine-tuning')\n",
    "        plt.quiver(0, 0, lora_x.item(), lora_y.item(), angles='xy', scale_units='xy', scale=1, color='g', label='LoRA Tuning')\n",
    "        plt.scatter(0, 0, c='r', s=100, label='Base Model')\n",
    "\n",
    "        # Set plot limits\n",
    "        max_magnitude = max(full_ft_mag, lora_mag).item()\n",
    "        plt.xlim(-0.1 * max_magnitude, 1.1 * max_magnitude)\n",
    "        plt.ylim(-0.1 * max_magnitude, 1.1 * max_magnitude)\n",
    "\n",
    "        plt.title(f\"Weight Change Visualization (Blocks {block_indices})\\nCosine Similarity: {cos_sim.item():.4f}, Angle: {angle.item():.2f}째\")\n",
    "        # plt.xlabel(\"Change Magnitude\")\n",
    "        # plt.ylabel(\"Change Direction\")\n",
    "\n",
    "        # Add magnitude annotations\n",
    "        plt.annotate(f'{full_ft_mag.item():.4f}', xy=(full_ft_x.item(), full_ft_y), xytext=(5, 5), textcoords='offset points')\n",
    "        plt.annotate(f'{lora_mag.item():.4f}', xy=(lora_x.item(), lora_y.item()), xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "        print(f\"Cosine Similarity: {cos_sim.item():.4f}\")\n",
    "        print(f\"Angle between vectors: {angle.item():.2f}째\")\n",
    "        print(f\"Magnitude of Full Fine-tuning change: {full_ft_mag.item():.4f}\")\n",
    "        print(f\"Magnitude of LoRA change: {lora_mag.item():.4f}\")\n",
    "\n",
    "    else:  # reference_point == 'origin'\n",
    "        # Calculate magnitudes\n",
    "        base_mag = torch.linalg.vector_norm(base_flat)\n",
    "        full_ft_mag = torch.linalg.vector_norm(full_ft_flat)\n",
    "        lora_mag = torch.linalg.vector_norm(lora_flat)\n",
    "        \n",
    "        # Calculate magnitudes of changed weights (just for checking)\n",
    "        full_ft_change = full_ft_flat - base_flat\n",
    "        lora_change = lora_flat - base_flat\n",
    "        full_ft_ch_mag = torch.linalg.vector_norm(full_ft_change)\n",
    "        lora_ch_mag = torch.linalg.vector_norm(lora_change)\n",
    "\n",
    "        # Calculate cosine similarities and angles\n",
    "        cos_sim_base_ft = cosine_similarity(base_flat, full_ft_flat)\n",
    "        cos_sim_base_lora = cosine_similarity(base_flat, lora_flat)\n",
    "        \n",
    "        angle_base_ft = torch.acos(cos_sim_base_ft) * 180 / np.pi\n",
    "        angle_base_lora = torch.acos(cos_sim_base_lora) * 180 / np.pi\n",
    "\n",
    "        # Calculate vector components (base along x-axis)\n",
    "        base_x = base_mag\n",
    "        base_y = 0\n",
    "        full_ft_x = full_ft_mag * torch.cos(torch.tensor(angle_base_ft * np.pi / 180))\n",
    "        full_ft_y = full_ft_mag * torch.sin(torch.tensor(angle_base_ft * np.pi / 180))\n",
    "        lora_x = lora_mag * torch.cos(torch.tensor(angle_base_lora * np.pi / 180))\n",
    "        lora_y = lora_mag * torch.sin(torch.tensor(angle_base_lora * np.pi / 180))\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.quiver(0, 0, base_x.item(), base_y, angles='xy', scale_units='xy', scale=1, color='r', label='Base Model')\n",
    "        plt.quiver(0, 0, full_ft_x.item(), full_ft_y.item(), angles='xy', scale_units='xy', scale=1, color='b', label='Full Fine-tuning')\n",
    "        plt.quiver(0, 0, lora_x.item(), lora_y.item(), angles='xy', scale_units='xy', scale=1, color='g', label='LoRA Tuning')\n",
    "        plt.scatter(0, 0, c='k', s=100, label='Origin')\n",
    "\n",
    "        # Set plot limits\n",
    "        max_magnitude = max(base_mag, full_ft_mag, lora_mag).item()\n",
    "        plt.xlim(-0.1 * max_magnitude, 1.1 * max_magnitude)\n",
    "        plt.ylim(-0.1 * max_magnitude, 1.1 * max_magnitude)\n",
    "\n",
    "        plt.title(f\"Weight Visualization (Blocks {block_indices})\")\n",
    "        # plt.xlabel(\"Weight Magnitude\")\n",
    "        # plt.ylabel(\"Weight Direction\")\n",
    "\n",
    "        # Add magnitude annotations\n",
    "        plt.annotate(f'{base_mag.item():.4f}', xy=(base_x.item(), base_y), xytext=(5, 5), textcoords='offset points')\n",
    "        plt.annotate(f'{full_ft_mag.item():.4f}', xy=(full_ft_x.item(), full_ft_y.item()), xytext=(5, 5), textcoords='offset points')\n",
    "        plt.annotate(f'{lora_mag.item():.4f}', xy=(lora_x.item(), lora_y.item()), xytext=(5, 5), textcoords='offset points')\n",
    "        \n",
    "        print(f\"Cosine Similarity (Base - Full FT): {cos_sim_base_ft.item():.4f}\")\n",
    "        print(f\"Cosine Similarity (Base - LoRA): {cos_sim_base_lora.item():.4f}\")\n",
    "        print(f\"Angle between Base and Full FT: {angle_base_ft.item():.2f}째\")\n",
    "        print(f\"Angle between Base and LoRA: {angle_base_lora.item():.2f}째\")\n",
    "        print(f\"Magnitude of Base Model weights: {base_mag.item():.4f}\")\n",
    "        print(f\"Magnitude of Full Fine-tuning weights: {full_ft_mag.item():.4f}\")\n",
    "        print(f\"Magnitude of LoRA weights: {lora_mag.item():.4f}\")\n",
    "        print(f\"Magnitude of FFT-Base: {full_ft_ch_mag.item():.4f}\")\n",
    "        print(f\"Magnitude of LoRA-Base weights: {lora_ch_mag.item():.4f}\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def analyze_layer_changes(base_weights, full_ft_weights, lora_weights, block_indices, reference_point):\n",
    "    for layer_type in ['q_proj', 'k_proj', 'v_proj', 'o_proj']:\n",
    "        layer_base = {k: v for k, v in base_weights.items() if layer_type in k}\n",
    "        layer_full_ft = {k: v for k, v in full_ft_weights.items() if layer_type in k}\n",
    "        layer_lora = {k: v for k, v in lora_weights.items() if layer_type in k}\n",
    "        \n",
    "        print(f\"\\nAnalyzing {layer_type} layers for blocks {block_indices}:\")\n",
    "        visualize_weight_changes(layer_base, layer_full_ft, layer_lora, block_indices, reference_point)\n",
    "\n",
    "# Load models\n",
    "base_model_name = \"upstage/SOLAR-10.7B-Instruct-v1.0\"\n",
    "full_ft_model_name = \"solar-privacy-merged1000\"\n",
    "lora_model_name = \"solar-lora-privacy-merged1000\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, base_model = load_model(base_model_name)\n",
    "_, full_ft_model = load_model(full_ft_model_name)\n",
    "_, lora_base_model = load_model(base_model_name)\n",
    "lora_model = PeftModel.from_pretrained(lora_base_model, lora_model_name)\n",
    "lora_model = lora_model.merge_and_unload()\n",
    "print(lora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_point = 'origin' #'origin'\n",
    "\n",
    "# Select which blocks to analyze\n",
    "block_indices = [0,1,2,3,4,5,6,7,8,9]\n",
    "# block_indices = [10,11,12,13,14,15,16,17,18,19]\n",
    "# block_indices = [20,21,22,23,24,25,26,27,28,29]\n",
    "# block_indices = [30,31,32,33,34,35,36,37,38,39]\n",
    "# block_indices = [40,41,42,43,44,45,46,47]\n",
    "\n",
    "# Get projection weights for selected blocks\n",
    "base_weights = get_projection_weights(base_model, block_indices)\n",
    "full_ft_weights = get_projection_weights(full_ft_model, block_indices)\n",
    "lora_weights = get_projection_weights(lora_model, block_indices)\n",
    "\n",
    "# Analyze all layers together for selected blocks\n",
    "print(f\"Analyzing all layers for blocks {block_indices}:\")\n",
    "visualize_weight_changes(base_weights, full_ft_weights, lora_weights, block_indices, reference_point)\n",
    "\n",
    "# Analyze attention and MLP layers separately for selected blocks\n",
    "analyze_layer_changes(base_weights, full_ft_weights, lora_weights, block_indices, reference_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_point = 'base' #'origin'\n",
    "\n",
    "# Select which blocks to analyze\n",
    "block_indices = [0,1,2,3,4,5,6,7,8,9]\n",
    "# block_indices = [10,11,12,13,14,15,16,17,18,19]\n",
    "# block_indices = [20,21,22,23,24,25,26,27,28,29]\n",
    "# block_indices = [30,31,32,33,34,35,36,37,38,39]\n",
    "# block_indices = [40,41,42,43,44,45,46,47]\n",
    "block_indices = list(range(48))\n",
    "\n",
    "# Get all weights for selected blocks\n",
    "base_weights = get_block_weights(base_model, block_indices)\n",
    "full_ft_weights = get_block_weights(full_ft_model, block_indices)\n",
    "lora_weights = get_block_weights(lora_model, block_indices)\n",
    "\n",
    "# Analyze all projection layers together for selected blocks\n",
    "print(f\"Analyzing all projection layers for blocks {block_indices}:\")\n",
    "visualize_weight_changes(base_weights, full_ft_weights, lora_weights, block_indices, reference_point)\n",
    "\n",
    "# Analyze each projection layer type separately for selected blocks\n",
    "analyze_layer_changes(base_weights, full_ft_weights, lora_weights, block_indices, reference_point)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
